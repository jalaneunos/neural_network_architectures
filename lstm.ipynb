{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHAvE5VWigSrlcdnRR7lWa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalaneunos/neural_network_architectures/blob/main/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8HDhfqxtYYD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "%pip install lightning --quiet\n",
        "import lightning as L\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(L.LightningModule):\n",
        "  def __init__(self):\n",
        "    # Initialize weight and bias tensors\n",
        "    super().__init__()\n",
        "    mean = torch.tensor(0.0)\n",
        "    std = torch.tensor(1.0)\n",
        "\n",
        "    self.ltm = torch.tensor(0.)\n",
        "    self.stm = torch.tensor(0.)\n",
        "\n",
        "    # Forget gate: percentage of old long term memory\n",
        "    self.forget_gate_stm = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "    self.forget_gate_input = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "    self.forget_gate_bias = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "\n",
        "    # Potential (new) long term memory\n",
        "    self.input_gate_stm = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "    self.input_gate_input = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "    self.input_gate_bias = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "    # Percentage of potential (new) long term memory\n",
        "    self.input_gate_percent_stm = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "    self.input_gate_percent_input = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "    self.input_gate_percent_bias = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "    # Percentage of potential (new) short term memory\n",
        "    self.output_gate_percent_stm = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "    self.output_gate_percent_input = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
        "    self.output_gate_percent_bias = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
        "\n",
        "\n",
        "  def lstm_unit(self, input_value):\n",
        "    forget_gate = F.sigmoid(self.stm * self.forget_gate_stm + input_value * self.forget_gate_input + self.forget_gate_bias)\n",
        "    retained_ltm = self.ltm * forget_gate\n",
        "\n",
        "    potential_ltm = F.tanh(self.stm * self.input_gate_stm + input_value * self.input_gate_input + self.input_gate_bias)\n",
        "    percentage_potential_ltm =  F.sigmoid(self.stm * self.input_gate_percent_stm + input_value * self.input_gate_percent_input + self.input_gate_percent_bias)\n",
        "    input_gate = potential_ltm * percentage_potential_ltm\n",
        "\n",
        "    new_ltm = retained_ltm + input_gate\n",
        "\n",
        "    potential_stm = F.tanh(new_ltm)\n",
        "    percent_potential_stm =  F.sigmoid(self.stm * self.output_gate_percent_stm + input_value * self.input_gate_percent_input + self.input_gate_percent_bias)\n",
        "\n",
        "    new_stm = potential_stm * percent_potential_stm\n",
        "\n",
        "    return new_stm, new_ltm\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.stm, self.ltm = torch.tensor(0.), torch.tensor(0.)\n",
        "    for data in input:\n",
        "      new_stm, new_ltm = self.lstm_unit(data)\n",
        "      self.stm, self.ltm = new_stm, new_ltm\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return Adam(self.parameters())\n",
        "\n",
        "  def training_step(self, batch, label):\n",
        "    self.forward(batch)\n",
        "    pred = self.stm\n",
        "    loss = (label - pred) ** 2\n",
        "    print(f\"Label: {label}, Predicted: {pred}, Loss: {loss}\")\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oSIqs3ujuJqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM()\n",
        "model.training_step(torch.tensor([0., 0.5, .25, 1]), 0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P71eq1o4MFJB",
        "outputId": "42b827b7-cc83-44c8-a762-73290bb87fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 0.0, Predicted: -0.1598021239042282, Loss: 0.02553671970963478\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0255, grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.training_step(torch.tensor([1., 0.5, .25, 1]), 1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1auFOC-eMbQs",
        "outputId": "ac1a0b94-7867-4ca2-f96b-d30a7f272cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1.0, Predicted: -0.17766152322292328, Loss: 1.386886715888977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.3869, grad_fn=<PowBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([0., 0.5, .25, 1])\n",
        "labels = torch.tensor([0.])"
      ],
      "metadata": {
        "id": "IlB2SCzSM_k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):  # replace num_epochs with the number of epochs\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        model.forward(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        pred = model.stm\n",
        "        loss = (labels - pred) ** 2\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "          print(f\"Epoch [{epoch}/{num_epochs}], Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HPJDUOWNRdm",
        "outputId": "6d8fa32a-a77c-4cbc-8990-683b41ab32cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/2000], Loss: 0.02553671970963478\n",
            "Epoch [100/2000], Loss: 0.011309489607810974\n",
            "Epoch [200/2000], Loss: 0.005834585055708885\n",
            "Epoch [300/2000], Loss: 0.0032741702161729336\n",
            "Epoch [400/2000], Loss: 0.0019022937631234527\n",
            "Epoch [500/2000], Loss: 0.001105964183807373\n",
            "Epoch [600/2000], Loss: 0.0006265657139010727\n",
            "Epoch [700/2000], Loss: 0.0003383951843716204\n",
            "Epoch [800/2000], Loss: 0.00017112806381192058\n",
            "Epoch [900/2000], Loss: 7.99399203970097e-05\n",
            "Epoch [1000/2000], Loss: 3.418698543100618e-05\n",
            "Epoch [1100/2000], Loss: 1.3321314327185974e-05\n",
            "Epoch [1200/2000], Loss: 4.72071997137391e-06\n",
            "Epoch [1300/2000], Loss: 1.52066695591202e-06\n",
            "Epoch [1400/2000], Loss: 4.451038364550186e-07\n",
            "Epoch [1500/2000], Loss: 1.182708899705176e-07\n",
            "Epoch [1600/2000], Loss: 2.846194924188694e-08\n",
            "Epoch [1700/2000], Loss: 6.18341511327003e-09\n",
            "Epoch [1800/2000], Loss: 1.2069324428765071e-09\n",
            "Epoch [1900/2000], Loss: 2.1100068914314818e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward(inputs)\n",
        "model.stm"
      ],
      "metadata": {
        "id": "RcEQUQBZNgzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51541253-ed3d-49c3-fe5f-d8516c913f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-5.7258e-06, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ZWdB8tgaoBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}